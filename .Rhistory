U_n=temp$U_n
W_n=temp$W_n
if(U_n>log(1/alpha)) cat(" We can reject the null hypothesis") else cat(" We can not reject the null hypothesis")
#dovremmo accettare H0
#ok
out=MLEdag(X,D=D,tau=0.35, mu=10, rho=1.2, trace_obj = F)
out$pval
D <- matrix(0, p, p)
D[9,1] = 1
D[1,2] = 1
D[2,6] = 1
alpha=0.05
#first connection
temp=log.LRT(X,D, links=F)
U_n=temp$U_n
W_n=temp$W_n
cat("U_n:", U_n, "   W_n:", W_n)
# non rigettiamo l'hp nulla quindi ok
out=MLEdag(X,D=D,tau=0.35, mu=10, rho=1.2, trace_obj = F)
out$pval
D <- matrix(0, p, p)
D[9,1] = 1
D[1,2] = 1
D[2,6] = 1
alpha=0.05
#first connection
temp=log.LRT(X,D, links=F)
U_n=temp$U_n
W_n=temp$W_n
cat("U_n:", U_n, "   W_n:", W_n)
# non rigettiamo l'hp nulla quindi ok
out=MLEdag(X,D=D,tau=0.35, mu=0.01, rho=1.2, trace_obj = F)
out$pval
D <- matrix(0, p, p)
D[9,1] = 1
D[1,2] = 1
D[2,6] = 1
alpha=0.05
#first connection
temp=log.LRT(X,D, links=F)
U_n=temp$U_n
W_n=temp$W_n
cat("U_n:", U_n, "   W_n:", W_n)
# non rigettiamo l'hp nulla quindi ok
out=MLEdag(X,D=D,tau=0.35, mu=0.1, rho=1.2, trace_obj = F)
out$pval
D <- matrix(0, p, p)
D[9,1] = 1
D[1,2] = 1
D[2,6] = 1
alpha=0.05
#first connection
temp=log.LRT(X,D, links=F)
U_n=temp$U_n
W_n=temp$W_n
cat("U_n:", U_n, "   W_n:", W_n)
# non rigettiamo l'hp nulla quindi ok
out=MLEdag(X,D=D,tau=0.35, mu=0.1, rho=1.2, trace_obj = F)
out$pval
D <- matrix(0, p, p)
D[9,1] = 1
D[1,2] = 1
D[2,6] = 1
alpha=0.05
#first connection
temp=log.LRT(X,D, links=F)
U_n=temp$U_n
W_n=temp$W_n
cat("U_n:", U_n, "   W_n:", W_n)
# non rigettiamo l'hp nulla quindi ok
out=MLEdag(X,D=D,tau=0.35, mu=1, rho=1.2, trace_obj = F)
out$pval
View(transform)
data=read.csv("data/cell_signaling/pma.csv",header=T,sep=",")
head(data,n=5)
X=data.matrix(data, rownames.force = NA)
#data will be our X matrix
p=11
#DATA TRANSFORMATION
for ( i in 1:length(X[2])){
X[,i]=scale(transform(X[,i]))
}
hist(X[,1])
hist(X[,1],breaks=20)
hist(X[,1],breaks=50)
hist(X[,2],breaks=50)
for ( i in 1:length(X[2])){
X[,i]=scale(transform(X[,i]))
}
hist(X[,2],breaks=50)
transform=function(column){
bc=boxcox(column~1,lambda=seq(-2,2));
best_lambda=bc$x[which(bc$y==max(bc$y))]
if (best_lambda==0) {
column=sapply(column,function(x) log(x))
}
else {
column=sapply(column,function(x) (x^best_lambda-1)/best_lambda )
}
}
data=read.csv("data/cell_signaling/pma.csv",header=T,sep=",")
head(data,n=5)
X=data.matrix(data, rownames.force = NA)
#data will be our X matrix
p=11
for ( i in 1:length(X[2])){
X[,i]=scale(transform(X[,i]))
}
hist(X[,2],breaks=50)
hist(X[,1],breaks=50)
hist(X[,4],breaks=50)
#FIRST CONNECTION: PIP2->
for ( i in 1:length(X[2])){
X[,i]=scale(transform(X[,i]))
}
transform=function(column){
bc=boxcox(column~1,lambda=seq(-5,5));
best_lambda=bc$x[which(bc$y==max(bc$y))]
if (best_lambda==0) {
column=sapply(column,function(x) log(x))
}
else {
column=sapply(column,function(x) (x^best_lambda-1)/best_lambda )
}
}
data=read.csv("data/cell_signaling/pma.csv",header=T,sep=",")
X=data.matrix(data, rownames.force = NA)
#data will be our X matrix
p=11
for ( i in 1:length(X[2])){
X[,i]=scale(transform(X[,i]))
}
data=read.csv("data/cell_signaling/pma.csv",header=T,sep=",")
data=read.csv("data/cell_signaling/original/pma.csv",header=T,sep=",")
X=data.matrix(data, rownames.force = NA)
transform=function(column){
bc=boxcox(column~1,lambda=seq(-5,5));
best_lambda=bc$x[which(bc$y==max(bc$y))]
if (best_lambda==0) {
column=sapply(column,function(x) log(x))
}
else {
column=sapply(column,function(x) (x^best_lambda-1)/best_lambda )
}
}
#DATA TRANSFORMATION
for ( i in 1:length(X[2])){
X[,i]=scale(transform(X[,i]))
}
hist(X[,4],breaks=50)
hist(X[,1],breaks=50)
for ( i in 1:length(X[2])){
temp=transform(X[,i])
X[,i]=scale(temp)
}
library(clrdag)
data=read.csv("data/cell_signaling/original/b2camp.csv",header=T,sep=",")
X=data.matrix(data, rownames.force = NA)
#data will be our X matrix
p=11
box_cox=function(column){
bc=boxcox(column~1,lambda=seq(-5,5));
best_lambda=bc$x[which(bc$y==max(bc$y))]
if (best_lambda==0) {
column=sapply(column,function(x) log(x))
}
else {
column=sapply(column,function(x) (x^best_lambda-1)/best_lambda )
}
return(column)
}
normalize=function(column){
column=scale(box_cox(column))
return(column)
}
#DATA TRANSFORMATION
for ( i in 1:dim(X)[2]){
X[,i]=normalize(X[,i])
}
hist(X[,6],breaks=50)
#FIRST CONNECTION: PIP2->PKC (columns 4  and column 9)
### H0: F = { (4,9) }, and A[F] = 0
D <- matrix(0, p, p)
D[4,9] = 1
alpha=0.05
MU=1.2
temp=log.LRT(X,D, links=T,mu=MU)
U_n=temp$U_n
W_n=temp$W_n
if(U_n>log(1/alpha)) cat(" We can reject the null hypothesis") else cat(" We can not reject the null hypothesis")
## OKKKK, we accept the null hypothesis
out=MLEdag(X=X,D=D,tau=0.35, mu=MU, rho=1.2, trace_obj = F)
out$pval
D <- matrix(0, p, p)
D[4,9] = 1
alpha=0.05
MU=1.2
temp=log.LRT(X,D, links=T,MU)
U_n=temp$U_n
W_n=temp$W_n
D <- matrix(0, p, p)
D[4,9] = 1
alpha=0.05
MU=1.2
temp=log.LRT(X,D, links=T,mu=MU)
library(clrdag)
compute.middle = function(X,A,j, p){
# Finding the indexes K = {k s.t. k is in [1,p]\j}
K = which((1:p)!=j)
# in k we have the indexes of the row without j
inners = apply(X[, K] * A[j, K], 1, sum) # n length vector containing the inner sums for each i-th sample
middle = sum((X[, j] - inners)^2)  # as a matter of fact in the middle we are working on the j-th column
return(middle)
}
sigma.estimator = function(X, A){
n = dim(X)[1]
p = dim(X)[2]
return(sum(sapply(1:p, function(j)compute.middle(X,A,j, p)))/(n*p))
}
log_likelihood = function(X, A, sigma.square){
n = dim(X)[1]
p = dim(X)[2]
return(-sum(sapply(1:p, function(j) (compute.middle(X,A,j,p)/(2*sigma.square)+(n/2*log(sigma.square))))))
}
inner_LRT_function.paths = function(X, X.tr, X.te, D, mu ){
# Computing all the A.h0 over the sparsity parameters 'k'
A.mles = lapply(1:sum(D), function(mu)MLEdag(X, D=D, tau=0.35, mu=mu, rho=1.2, trace_obj = F))
A.h0s  = lapply(A.mles, function(a)a$A.H0)
A.h1s  = lapply(A.mles, function(a)a$A.H1)
# For each A.h0 compute the associated sigma
sigmas.0 = t(sapply(A.h0s, function(a)sigma.estimator(X.tr, a)))
sigmas.1 = t(sapply(A.h1s, function(a)sigma.estimator(X.te, a)))
# Computing the likelihoods of each pair (A.h0, sigma.h0)
likelihoods.0 = t(sapply(1:length(sigmas.0), function(idx)log_likelihood(X.tr, A.h0s[[idx]], sigmas.0[idx])))
likelihoods.1 = t(sapply(1:length(sigmas.1), function(idx)log_likelihood(X.tr, A.h1s[[idx]], sigmas.1[idx])))
# Finding the idx that give us the maximum likelihood
mle_idx.0 = which(likelihoods.0==max(likelihoods.0))[1] # maximum likelihood over h0
mle_idx.1 = which(likelihoods.1==max(likelihoods.1))[1] # maximum likelihood over h0
return (likelihoods.1[mle_idx.1]-likelihoods.0[mle_idx.0])
#return(list(U.n=exp(log_likelihood(X.tr, A, sigma.unconstrained)-likelihoods[mle_idx]), A.h0=A.h0s[[mle_idx]]))
}
inner_LRT_function.links = function(X, X.tr, X.te, D, mu){
tmp = MLEdag(X = X, D = D, tau = 0.35, mu = mu,
rho = 1.2, trace_obj = FALSE)
A.h0 = tmp$A.H0
A = tmp$A.H1
sigma.h0 = sigma.estimator(X.tr, A.h0)
sigma.unconstrained = sigma.estimator(X.te, A)
return(log_likelihood(X.tr, A, sigma.unconstrained)-log_likelihood(X.tr, A.h0, sigma.h0))
}
log.LRT = function(X,D, links=T, mu){
n=dim(X)[1]
X.tr = X[1:(n%/%2),]
X.te = X[(n%/%2+1):n,]
if(links){
U_n = inner_LRT_function.links(X, X.tr, X.te, D, mu)
U_n.swap = inner_LRT_function.links(X, X.te, X.tr, D, mu)
}
else{
U_n = inner_LRT_function.paths(X, X.tr, X.te, D, mu)
U_n.swap = inner_LRT_function.paths(X, X.te, X.tr, D,mu)
}
return(list(links = links, U_n = U_n, W_n = (log((exp(U_n)+exp(U_n.swap))/2))))
}
data=read.csv("data/cell_signaling/original/b2camp.csv",header=T,sep=",")
X=data.matrix(data, rownames.force = NA)
#data will be our X matrix
p=11
box_cox=function(column){
bc=boxcox(column~1,lambda=seq(-5,5));
best_lambda=bc$x[which(bc$y==max(bc$y))]
if (best_lambda==0) {
column=sapply(column,function(x) log(x))
}
else {
column=sapply(column,function(x) (x^best_lambda-1)/best_lambda )
}
return(column)
}
normalize=function(column){
column=scale(box_cox(column))
return(column)
}
#DATA TRANSFORMATION
for ( i in 1:dim(X)[2]){
X[,i]=normalize(X[,i])
}
box_cox=function(column){
bc=boxcox(column~1,lambda=seq(-5,5));
best_lambda=bc$x[which(bc$y==max(bc$y))]
if (best_lambda==0) {
column=sapply(column,function(x) log(x))
}
else {
column=sapply(column,function(x) (x^best_lambda-1)/best_lambda )
}
return(column)
}
normalize=function(column){
column=scale(box_cox(column))
return(column)
}
#DATA TRANSFORMATION
for ( i in 1:dim(X)[2]){
X[,i]=normalize(X[,i])
}
#DATA TRANSFORMATION
for ( i in 1:dim(X)[2]){
X[,i]=normalize(X[,i])
}
bc=boxcox(X[,1]~1,lambda=seq(-5,5));
library(clrdag)
compute.middle = function(X,A,j, p){
# Finding the indexes K = {k s.t. k is in [1,p]\j}
K = which((1:p)!=j)
# in k we have the indexes of the row without j
inners = apply(X[, K] * A[j, K], 1, sum) # n length vector containing the inner sums for each i-th sample
middle = sum((X[, j] - inners)^2)  # as a matter of fact in the middle we are working on the j-th column
return(middle)
}
sigma.estimator = function(X, A){
n = dim(X)[1]
p = dim(X)[2]
return(sum(sapply(1:p, function(j)compute.middle(X,A,j, p)))/(n*p))
}
log_likelihood = function(X, A, sigma.square){
n = dim(X)[1]
p = dim(X)[2]
return(-sum(sapply(1:p, function(j) (compute.middle(X,A,j,p)/(2*sigma.square)+(n/2*log(sigma.square))))))
}
inner_LRT_function.paths = function(X, X.tr, X.te, D, mu ){
# Computing all the A.h0 over the sparsity parameters 'k'
A.mles = lapply(1:sum(D), function(mu)MLEdag(X, D=D, tau=0.35, mu=mu, rho=1.2, trace_obj = F))
A.h0s  = lapply(A.mles, function(a)a$A.H0)
A.h1s  = lapply(A.mles, function(a)a$A.H1)
# For each A.h0 compute the associated sigma
sigmas.0 = t(sapply(A.h0s, function(a)sigma.estimator(X.tr, a)))
sigmas.1 = t(sapply(A.h1s, function(a)sigma.estimator(X.te, a)))
# Computing the likelihoods of each pair (A.h0, sigma.h0)
likelihoods.0 = t(sapply(1:length(sigmas.0), function(idx)log_likelihood(X.tr, A.h0s[[idx]], sigmas.0[idx])))
likelihoods.1 = t(sapply(1:length(sigmas.1), function(idx)log_likelihood(X.tr, A.h1s[[idx]], sigmas.1[idx])))
# Finding the idx that give us the maximum likelihood
mle_idx.0 = which(likelihoods.0==max(likelihoods.0))[1] # maximum likelihood over h0
mle_idx.1 = which(likelihoods.1==max(likelihoods.1))[1] # maximum likelihood over h0
return (likelihoods.1[mle_idx.1]-likelihoods.0[mle_idx.0])
#return(list(U.n=exp(log_likelihood(X.tr, A, sigma.unconstrained)-likelihoods[mle_idx]), A.h0=A.h0s[[mle_idx]]))
}
inner_LRT_function.links = function(X, X.tr, X.te, D, mu){
tmp = MLEdag(X = X, D = D, tau = 0.35, mu = mu,
rho = 1.2, trace_obj = FALSE)
A.h0 = tmp$A.H0
A = tmp$A.H1
sigma.h0 = sigma.estimator(X.tr, A.h0)
sigma.unconstrained = sigma.estimator(X.te, A)
return(log_likelihood(X.tr, A, sigma.unconstrained)-log_likelihood(X.tr, A.h0, sigma.h0))
}
log.LRT = function(X,D, links=T, mu){
n=dim(X)[1]
X.tr = X[1:(n%/%2),]
X.te = X[(n%/%2+1):n,]
if(links){
U_n = inner_LRT_function.links(X, X.tr, X.te, D, mu)
U_n.swap = inner_LRT_function.links(X, X.te, X.tr, D, mu)
}
else{
U_n = inner_LRT_function.paths(X, X.tr, X.te, D, mu)
U_n.swap = inner_LRT_function.paths(X, X.te, X.tr, D,mu)
}
return(list(links = links, U_n = U_n, W_n = (log((exp(U_n)+exp(U_n.swap))/2))))
}
data=read.csv("data/cell_signaling/original/b2camp.csv",header=T,sep=",")
X=data.matrix(data, rownames.force = NA)
#data will be our X matrix
p=11
box_cox=function(column){
bc=boxcox(column~1,lambda=seq(-5,5));
best_lambda=bc$x[which(bc$y==max(bc$y))]
if (best_lambda==0) {
column=sapply(column,function(x) log(x))
}
else {
column=sapply(column,function(x) (x^best_lambda-1)/best_lambda )
}
return(column)
}
normalize=function(column){
column=scale(box_cox(column))
return(column)
}
#DATA TRANSFORMATION
for ( i in 1:dim(X)[2]){
X[,i]=normalize(X[,i])
}
hist(X[,6],breaks=50)
bc=boxcox(X[,1]~1,lambda=seq(-5,5));
help(boxcox)
??boxcox
install.packages("MASS")
bc=boxcox(X[,1]~1,lambda=seq(-5,5));
library(clrdag)
compute.middle = function(X,A,j, p){
# Finding the indexes K = {k s.t. k is in [1,p]\j}
K = which((1:p)!=j)
# in k we have the indexes of the row without j
inners = apply(X[, K] * A[j, K], 1, sum) # n length vector containing the inner sums for each i-th sample
middle = sum((X[, j] - inners)^2)  # as a matter of fact in the middle we are working on the j-th column
return(middle)
}
sigma.estimator = function(X, A){
n = dim(X)[1]
p = dim(X)[2]
return(sum(sapply(1:p, function(j)compute.middle(X,A,j, p)))/(n*p))
}
log_likelihood = function(X, A, sigma.square){
n = dim(X)[1]
p = dim(X)[2]
return(-sum(sapply(1:p, function(j) (compute.middle(X,A,j,p)/(2*sigma.square)+(n/2*log(sigma.square))))))
}
inner_LRT_function.paths = function(X, X.tr, X.te, D, mu ){
# Computing all the A.h0 over the sparsity parameters 'k'
A.mles = lapply(1:sum(D), function(mu)MLEdag(X, D=D, tau=0.35, mu=mu, rho=1.2, trace_obj = F))
A.h0s  = lapply(A.mles, function(a)a$A.H0)
A.h1s  = lapply(A.mles, function(a)a$A.H1)
# For each A.h0 compute the associated sigma
sigmas.0 = t(sapply(A.h0s, function(a)sigma.estimator(X.tr, a)))
sigmas.1 = t(sapply(A.h1s, function(a)sigma.estimator(X.te, a)))
# Computing the likelihoods of each pair (A.h0, sigma.h0)
likelihoods.0 = t(sapply(1:length(sigmas.0), function(idx)log_likelihood(X.tr, A.h0s[[idx]], sigmas.0[idx])))
likelihoods.1 = t(sapply(1:length(sigmas.1), function(idx)log_likelihood(X.tr, A.h1s[[idx]], sigmas.1[idx])))
# Finding the idx that give us the maximum likelihood
mle_idx.0 = which(likelihoods.0==max(likelihoods.0))[1] # maximum likelihood over h0
mle_idx.1 = which(likelihoods.1==max(likelihoods.1))[1] # maximum likelihood over h0
return (likelihoods.1[mle_idx.1]-likelihoods.0[mle_idx.0])
#return(list(U.n=exp(log_likelihood(X.tr, A, sigma.unconstrained)-likelihoods[mle_idx]), A.h0=A.h0s[[mle_idx]]))
}
inner_LRT_function.links = function(X, X.tr, X.te, D, mu){
tmp = MLEdag(X = X, D = D, tau = 0.35, mu = mu,
rho = 1.2, trace_obj = FALSE)
A.h0 = tmp$A.H0
A = tmp$A.H1
sigma.h0 = sigma.estimator(X.tr, A.h0)
sigma.unconstrained = sigma.estimator(X.te, A)
return(log_likelihood(X.tr, A, sigma.unconstrained)-log_likelihood(X.tr, A.h0, sigma.h0))
}
log.LRT = function(X,D, links=T, mu){
n=dim(X)[1]
X.tr = X[1:(n%/%2),]
X.te = X[(n%/%2+1):n,]
if(links){
U_n = inner_LRT_function.links(X, X.tr, X.te, D, mu)
U_n.swap = inner_LRT_function.links(X, X.te, X.tr, D, mu)
}
else{
U_n = inner_LRT_function.paths(X, X.tr, X.te, D, mu)
U_n.swap = inner_LRT_function.paths(X, X.te, X.tr, D,mu)
}
return(list(links = links, U_n = U_n, W_n = (log((exp(U_n)+exp(U_n.swap))/2))))
}
data=read.csv("data/cell_signaling/original/pma.csv",header=T,sep=",")
X=data.matrix(data, rownames.force = NA)
#data will be our X matrix
p=11
box_cox=function(column){
bc=boxcox(column~1,lambda=seq(-5,5));
best_lambda=bc$x[which(bc$y==max(bc$y))]
if (best_lambda==0) {
column=sapply(column,function(x) log(x))
}
else {
column=sapply(column,function(x) (x^best_lambda-1)/best_lambda )
}
return(column)
}
normalize=function(column){
column=scale(box_cox(column))
return(column)
}
for ( i in 1:dim(X)[2]){
X[,i]=normalize(X[,i])
}
library(MASS)
remove.packages("MASS")
install.packages("MASS")
for ( i in 1:dim(X)[2]){
X[,i]=normalize(X[,i])
}
library(MASS)
remove.packages("MASS")
install.packages("MASS")
box_cox=function(column){
bc=boxcox(column~1,lambda=seq(-5,5));
best_lambda=bc$x[which(bc$y==max(bc$y))]
if (best_lambda==0) {
column=sapply(column,function(x) log(x))
}
else {
column=sapply(column,function(x) (x^best_lambda-1)/best_lambda )
}
return(column)
}
normalize=function(column){
column=scale(box_cox(column))
return(column)
}
#DATA TRANSFORMATION
for ( i in 1:dim(X)[2]){
X[,i]=normalize(X[,i])
}
data=read.csv("data/cell_signaling/normalized_and_scaled/pma.csv",header=T,sep=",")
X=data.matrix(data, rownames.force = NA)
p=11
hist(X[,6],breaks=50)
